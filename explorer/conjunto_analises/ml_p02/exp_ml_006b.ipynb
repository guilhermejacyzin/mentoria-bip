{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d47cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== MÉTRICAS (TESTE 20% FINAL) ==========\n",
      "Total linhas: 50159\n",
      "Índice corte (80%): 40127\n",
      "Treino: (40127, 37) | Teste: (10032, 37)\n",
      "scale_pos_weight = 3.6784\n",
      "threshold = 0.5\n",
      "\n",
      "Matriz de confusão:\n",
      "[[6750 1138]\n",
      " [ 494 1650]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9318    0.8557    0.8921      7888\n",
      "           1     0.5918    0.7696    0.6691      2144\n",
      "\n",
      "    accuracy                         0.8373     10032\n",
      "   macro avg     0.7618    0.8127    0.7806     10032\n",
      "weighted avg     0.8591    0.8373    0.8445     10032\n",
      "\n",
      "\n",
      "Acurácia: 83.73%\n",
      "Precisão: 59.18%\n",
      "Recall: 76.96%\n",
      "F1: 66.91%\n",
      "ROC-AUC: 0.8996\n",
      "\n",
      "✅ ARQUIVO GERADO COM SUCESSO!\n",
      "Arquivo: tabela_previsoes_xgb.csv\n",
      "Linhas: 10032\n",
      "Colunas: 10\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SCRIPT COMPLETO (REFATORADO DO SEU NOTEBOOK exp_ml_006.ipynb)\n",
    "# Gera: tabela_previsoes_xgb.csv\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0) IMPORTS\n",
    "# -----------------------------\n",
    "\n",
    "# pandas: leitura e manipulação do dataset em formato de tabela (DataFrame)\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: operações numéricas auxiliares\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn: pré-processamento e pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# xgboost: modelo\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) CONFIGURAÇÕES (AJUSTE AQUI)\n",
    "# -----------------------------\n",
    "\n",
    "# caminho do seu dataset (CSV)\n",
    "# - se estiver na mesma pasta do script, basta deixar o nome do arquivo\n",
    "CAMINHO_DATASET = \"australia_clima_v8.csv\"\n",
    "\n",
    "# nome do arquivo CSV final (saída) para o Power BI\n",
    "CAMINHO_SAIDA = \"tabela_previsoes_xgb.csv\"\n",
    "\n",
    "# nome da coluna alvo (target) - exatamente como no seu notebook\n",
    "TARGET = \"chove_amanha_vtr\"\n",
    "\n",
    "# colunas que você removeu como \"irrelevantes\" no seu notebook\n",
    "# - \"data\" não entra no modelo porque é usada para split temporal e para BI\n",
    "# - \"choveu_hoje_fex\" você removeu no seu código\n",
    "COLUNAS_PARA_REMOVER = [\"data\", \"choveu_hoje_fex\"]\n",
    "\n",
    "# proporção temporal do split (80% treino, 20% teste)\n",
    "PROPORCAO_TREINO = 0.8\n",
    "\n",
    "# threshold padrão para transformar probabilidade em classe (0/1)\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# “apelido” da versão do modelo (para rastreabilidade no Power BI)\n",
    "MODELO_NOME = \"xgb_refatorado_v1\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) CARREGAR O DATASET (IGUAL SEU NOTEBOOK, SÓ QUE PORTÁVEL)\n",
    "# -----------------------------\n",
    "\n",
    "# df recebe o dataset carregado do CSV\n",
    "df = pd.read_csv(r'C:\\Users\\JacyzinGuilherme(Bip\\mentoria-bip\\dados_editados\\australia_clima_v8.csv', sep=',')\n",
    "\n",
    "# -----------------------------\n",
    "# 3) CONVERTER COLUNA \"data\" E ORDENAR (SPLIT TEMPORAL)\n",
    "# -----------------------------\n",
    "\n",
    "# converte a coluna 'data' para datetime, transformando textos em datas reais\n",
    "# - errors=\"coerce\" converte valores inválidos em NaT (nulo de datetime)\n",
    "df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\")\n",
    "\n",
    "# remove linhas onde a 'data' ficou inválida (NaT),\n",
    "# porque sem data não existe split temporal honesto\n",
    "df = df.dropna(subset=[\"data\"]).copy()\n",
    "\n",
    "# ordena do mais antigo para o mais recente (igual seu notebook)\n",
    "df = df.sort_values(by=\"data\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) DEFINIR TARGET E PREPARAR DF DE MODELAGEM (IGUAL SEU FLUXO)\n",
    "# -----------------------------\n",
    "\n",
    "# remove colunas irrelevantes (data e choveu_hoje_fex) do dataframe de modelagem\n",
    "# - errors=\"ignore\" evita quebrar se uma coluna não existir por algum motivo\n",
    "df_modelo = df.drop(columns=COLUNAS_PARA_REMOVER, errors=\"ignore\").copy()\n",
    "\n",
    "# garante que o target exista\n",
    "if TARGET not in df_modelo.columns:\n",
    "    raise ValueError(\n",
    "        f\"A coluna target '{TARGET}' não foi encontrada no dataset. \"\n",
    "        f\"Colunas disponíveis: {list(df_modelo.columns)}\"\n",
    "    )\n",
    "\n",
    "# remove linhas onde o target esteja nulo (não dá para treinar nem avaliar)\n",
    "df_modelo = df_modelo.dropna(subset=[TARGET]).copy()\n",
    "\n",
    "# força o target a ser inteiro 0/1\n",
    "df_modelo[TARGET] = df_modelo[TARGET].astype(int)\n",
    "\n",
    "# separa X (features) e y (target)\n",
    "X = df_modelo.drop(columns=[TARGET], errors=\"ignore\")\n",
    "y = df_modelo[TARGET]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REMOVER TODAS AS COLUNAS *_isna (IGUAL SEU NOTEBOOK)\n",
    "# -----------------------------\n",
    "\n",
    "# identifica colunas que terminam com \"_isna\"\n",
    "colunas_isna = [c for c in X.columns if c.endswith(\"_isna\")]\n",
    "\n",
    "# remove essas colunas do X\n",
    "X = X.drop(columns=colunas_isna, errors=\"ignore\").copy()\n",
    "\n",
    "# remove essas colunas também do df_modelo (para manter consistência)\n",
    "df_modelo = df_modelo.drop(columns=colunas_isna, errors=\"ignore\").copy()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 6) SPLIT TEMPORAL 80/20 POR ÍNDICE (IGUAL SEU NOTEBOOK)\n",
    "# -----------------------------\n",
    "\n",
    "# total_linhas recebe o total de linhas do df_modelo\n",
    "total_linhas = len(df_modelo)\n",
    "\n",
    "# indice_corte separa treino e teste (80% do começo para treino)\n",
    "indice_corte = int(total_linhas * PROPORCAO_TREINO)\n",
    "\n",
    "# X_train pega do início até o corte\n",
    "X_train = X.iloc[:indice_corte].copy()\n",
    "\n",
    "# X_test pega do corte até o final\n",
    "X_test = X.iloc[indice_corte:].copy()\n",
    "\n",
    "# y_train pega do início até o corte\n",
    "y_train = y.iloc[:indice_corte].copy()\n",
    "\n",
    "# y_test pega do corte até o final\n",
    "y_test = y.iloc[indice_corte:].copy()\n",
    "\n",
    "# também vamos guardar as datas correspondentes ao teste para exportar na tabela final\n",
    "# atenção: como removemos 'data' de df_modelo, pegamos da base original df (ordenada)\n",
    "# mas precisamos alinhar índices:\n",
    "# - como df_modelo veio de df com drop de colunas, a ordem e o index são os mesmos\n",
    "data_test = df.iloc[indice_corte:][\"data\"].copy()\n",
    "\n",
    "# também precisamos da localidade para BI (se existir)\n",
    "# - se não existir, a gente cria uma coluna “desconhecida”\n",
    "if \"localidade\" in df.columns:\n",
    "    localidade_test = df.iloc[indice_corte:][\"localidade\"].astype(str).copy()\n",
    "else:\n",
    "    localidade_test = pd.Series([\"desconhecida\"] * len(X_test))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 7) SEPARAR COLUNAS NUMÉRICAS E CATEGÓRICAS (IGUAL SEU NOTEBOOK)\n",
    "# -----------------------------\n",
    "\n",
    "# colunas categóricas: object ou category\n",
    "colunas_categoricas = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# colunas numéricas: int64/float64 (ou int32/float32 também, por segurança)\n",
    "colunas_numericas = X_train.select_dtypes(include=[\"int64\", \"float64\", \"int32\", \"float32\"]).columns.tolist()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 8) PREPROCESSADOR IGUAL O SEU \"preprocessor_rf\"\n",
    "#    - OneHot nas categóricas\n",
    "#    - passthrough nas numéricas\n",
    "# -----------------------------\n",
    "\n",
    "# OneHotEncoder:\n",
    "# - handle_unknown=\"ignore\": se aparecer categoria nova no teste, não quebra\n",
    "# - sparse_output=False: retorna matriz densa (igual seu notebook)\n",
    "transformador_categorico = OneHotEncoder(\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# ColumnTransformer:\n",
    "# - aplica onehot nas categóricas\n",
    "# - mantém numéricas como estão (\"passthrough\")\n",
    "preprocessador = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", transformador_categorico, colunas_categoricas),\n",
    "        (\"num\", \"passthrough\", colunas_numericas),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 9) SCALE_POS_WEIGHT (IGUAL SEU NOTEBOOK)\n",
    "# -----------------------------\n",
    "\n",
    "# n0: quantidade de classe 0 no treino\n",
    "n0 = int((y_train == 0).sum())\n",
    "\n",
    "# n1: quantidade de classe 1 no treino\n",
    "n1 = int((y_train == 1).sum())\n",
    "\n",
    "# evita divisão por zero (caso extremamente improvável)\n",
    "if n1 == 0:\n",
    "    scale_pos_weight = 1.0\n",
    "else:\n",
    "    scale_pos_weight = n0 / n1\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 10) MODELO XGBOOST (ALINHADO AO SEU NOTEBOOK)\n",
    "# -----------------------------\n",
    "# Aqui eu vou manter o núcleo do seu modelo:\n",
    "# - n_estimators\n",
    "# - learning_rate\n",
    "# - max_depth\n",
    "# - subsample\n",
    "# - colsample_bytree\n",
    "# - reg_lambda\n",
    "# - objective\n",
    "# - eval_metric=\"aucpr\" (como no seu)\n",
    "# - scale_pos_weight (como no seu)\n",
    "# - random_state\n",
    "# - n_jobs\n",
    "\n",
    "modelo_xgb = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.04,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# pipeline final:\n",
    "# 1) preprocessa (onehot + passthrough)\n",
    "# 2) treina XGBoost\n",
    "pipeline_xgb = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessamento\", preprocessador),\n",
    "        (\"modelo\", modelo_xgb)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 11) TREINAR (SOMENTE NO TREINO)\n",
    "# -----------------------------\n",
    "\n",
    "# fit aprende:\n",
    "# - mapeamento do one-hot (categorias existentes no treino)\n",
    "# - e então treina o XGBoost no espaço transformado\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 12) PREVER NO TESTE (FUTURO)\n",
    "# -----------------------------\n",
    "\n",
    "# probabilidade de classe 1 (chuva)\n",
    "y_proba_xgb = pipeline_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# classe prevista aplicando threshold\n",
    "y_pred_xgb = (y_proba_xgb >= THRESHOLD).astype(int)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 13) (OPCIONAL) IMPRIMIR MÉTRICAS PARA CONFERÊNCIA\n",
    "# -----------------------------\n",
    "\n",
    "print(\"========== MÉTRICAS (TESTE 20% FINAL) ==========\")\n",
    "print(f\"Total linhas: {total_linhas}\")\n",
    "print(f\"Índice corte (80%): {indice_corte}\")\n",
    "print(f\"Treino: {X_train.shape} | Teste: {X_test.shape}\")\n",
    "print(f\"scale_pos_weight = {scale_pos_weight:.4f}\")\n",
    "print(f\"threshold = {THRESHOLD}\")\n",
    "\n",
    "print(\"\\nMatriz de confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred_xgb, digits=4))\n",
    "\n",
    "print(\"\\nAcurácia:\", f\"{accuracy_score(y_test, y_pred_xgb)*100:.2f}%\")\n",
    "print(\"Precisão:\", f\"{precision_score(y_test, y_pred_xgb, zero_division=0)*100:.2f}%\")\n",
    "print(\"Recall:\", f\"{recall_score(y_test, y_pred_xgb, zero_division=0)*100:.2f}%\")\n",
    "print(\"F1:\", f\"{f1_score(y_test, y_pred_xgb, zero_division=0)*100:.2f}%\")\n",
    "\n",
    "# ROC-AUC pode falhar se o y_test tiver só uma classe (raro)\n",
    "try:\n",
    "    print(\"ROC-AUC:\", f\"{roc_auc_score(y_test, y_proba_xgb):.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC: não calculado (motivo:\", str(e), \")\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 14) MONTAR A TABELA FINAL PARA O POWER BI\n",
    "# -----------------------------\n",
    "\n",
    "# cutoff_date: primeira data do conjunto de teste\n",
    "cutoff_date = pd.to_datetime(data_test.min())\n",
    "\n",
    "# train_end_date: última data do conjunto de treino\n",
    "train_end_date = pd.to_datetime(df.iloc[:indice_corte][\"data\"].max())\n",
    "\n",
    "# test_start_date: primeira data do conjunto de teste (igual cutoff_date na prática)\n",
    "test_start_date = pd.to_datetime(data_test.min())\n",
    "\n",
    "# tabela_previsoes_xgb: dataframe final que o Power BI vai consumir\n",
    "tabela_previsoes_xgb = pd.DataFrame({\n",
    "    # data: a data real de cada linha prevista (teste)\n",
    "    \"data\": pd.to_datetime(data_test).dt.date,\n",
    "\n",
    "    # localidade: a localidade correspondente (se existir)\n",
    "    \"localidade\": localidade_test.values,\n",
    "\n",
    "    # y_true: verdade (o que realmente aconteceu)\n",
    "    \"y_true\": y_test.values.astype(int),\n",
    "\n",
    "    # y_pred: classe prevista pelo modelo (0/1)\n",
    "    \"y_pred\": y_pred_xgb.astype(int),\n",
    "\n",
    "    # y_proba: probabilidade do modelo para classe 1 (chuva)\n",
    "    \"y_proba\": y_proba_xgb.astype(float),\n",
    "\n",
    "    # metadados úteis para BI / rastreabilidade\n",
    "    \"modelo\": MODELO_NOME,\n",
    "    \"threshold\": THRESHOLD,\n",
    "    \"cutoff_date\": cutoff_date.date(),\n",
    "    \"train_end_date\": train_end_date.date(),\n",
    "    \"test_start_date\": test_start_date.date()\n",
    "})\n",
    "\n",
    "# ordena para ficar “bonito” e consistente no BI\n",
    "tabela_previsoes_xgb = tabela_previsoes_xgb.sort_values(by=[\"data\", \"localidade\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 15) EXPORTAR CSV FINAL\n",
    "# -----------------------------\n",
    "\n",
    "tabela_previsoes_xgb.to_csv(r'C:\\Users\\JacyzinGuilherme(Bip\\mentoria-bip\\dados_editados\\tabela_previsoes_xgb.csv', index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n✅ ARQUIVO GERADO COM SUCESSO!\")\n",
    "print(\"Arquivo:\", CAMINHO_SAIDA)\n",
    "print(\"Linhas:\", len(tabela_previsoes_xgb))\n",
    "print(\"Colunas:\", tabela_previsoes_xgb.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd636742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
